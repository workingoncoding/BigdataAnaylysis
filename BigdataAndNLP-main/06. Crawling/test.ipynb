{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO/8306wuPW3opRF6BDUYLB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### 참조1: https://somjang.tistory.com/entry/Python-selenium%EA%B3%BC-BeautifulSoup%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%98%EC%97%AC-%EB%84%A4%EC%9D%B4%EB%B2%84-%EB%89%B4%EC%8A%A4-%EA%B8%B0%EC%82%AC-%ED%81%AC%EB%A1%A4%EB%A7%81%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95\n","\n","### 참조2: https://aytekin.tistory.com/48\n","\n","### 참조3: https://book.coalastudy.com/data_crawling/week3/stage3"],"metadata":{"id":"DwBhRdzcWW5U"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mh8KBWMnUWmX","executionInfo":{"status":"ok","timestamp":1648635321888,"user_tz":-540,"elapsed":44863,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"ed851984-3016-4ca7-95f6-ae293d1a77ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.1.3-py3-none-any.whl (968 kB)\n","\u001b[K     |████████████████████████████████| 968 kB 4.3 MB/s \n","\u001b[?25hCollecting trio~=0.17\n","  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n","\u001b[K     |████████████████████████████████| 359 kB 41.5 MB/s \n","\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 68.2 MB/s \n","\u001b[?25hCollecting trio-websocket~=0.9\n","  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Collecting sniffio\n","  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n","Collecting async-generator>=1.9\n","  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n","Collecting outcome\n","  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n","Collecting wsproto>=0.14\n","  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n","Collecting pyOpenSSL>=0.14\n","  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 3.8 MB/s \n","\u001b[?25hCollecting cryptography>=1.3.4\n","  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 47.9 MB/s \n","\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n","Collecting h11<1,>=0.9.0\n","  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (3.10.0.2)\n","Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed async-generator-1.10 cryptography-36.0.2 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.3 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 urllib3-1.26.9 wsproto-1.1.0\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n","Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:13 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [80.8 kB]\n","Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,109 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [903 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,264 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.9 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n","Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,830 kB]\n","Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [946 kB]\n","Get:25 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,484 kB]\n","Get:26 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [937 kB]\n","Get:27 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,660 kB]\n","Get:28 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n","Get:29 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.3 kB]\n","Fetched 14.7 MB in 4s (3,609 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n","Suggested packages:\n","  webaccounts-chromium-extension unity-chromium-extension\n","The following NEW packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-chromedriver\n","  chromium-codecs-ffmpeg-extra\n","0 upgraded, 4 newly installed, 0 to remove and 79 not upgraded.\n","Need to get 88.3 MB of archives.\n","After this operation, 294 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 99.0.4844.84-0ubuntu0.18.04.1 [1,142 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 99.0.4844.84-0ubuntu0.18.04.1 [77.7 MB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 99.0.4844.84-0ubuntu0.18.04.1 [4,397 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 99.0.4844.84-0ubuntu0.18.04.1 [5,092 kB]\n","Fetched 88.3 MB in 4s (24.2 MB/s)\n","Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n","(Reading database ... 156210 files and directories currently installed.)\n","Preparing to unpack .../chromium-codecs-ffmpeg-extra_99.0.4844.84-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-codecs-ffmpeg-extra (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser.\n","Preparing to unpack .../chromium-browser_99.0.4844.84-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-browser (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser-l10n.\n","Preparing to unpack .../chromium-browser-l10n_99.0.4844.84-0ubuntu0.18.04.1_all.deb ...\n","Unpacking chromium-browser-l10n (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_99.0.4844.84-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Setting up chromium-codecs-ffmpeg-extra (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser (99.0.4844.84-0ubuntu0.18.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser-l10n (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.63.0)\n"]}],"source":["#이 부분은 처음 한번만 실행하면 됌.\n","!pip install selenium\n","!apt-get update\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n","!pip install tqdm\n","!pip install bs4\n","!pip install lxml"]},{"cell_type":"code","source":["# -*- coding: UTF-8 -*-\n","import time\n","from selenium import webdriver as wd\n","from tqdm import tqdm\n","from datetime import datetime\n","import os\n"," \n","#Colab에선 웹브라우저 창이 뜨지 않으므로 별도 설정한다.\n"," \n","options = wd.ChromeOptions()\n","options.add_argument('--headless')        # Head-less 설정\n","options.add_argument('--no-sandbox')\n","options.add_argument('--disable-dev-shm-usage')\n","driver = wd.Chrome('chromedriver', options=options)\n"," \n","#해당 url로 이동\n","url = \"https://www.naver.com/\" \n","driver.get(url)\n"," \n","update = driver.find_element_by_css_selector('#NM_TS_ROLLING_WRAP > div > div')\n","print(update.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOUeC3osU0mj","executionInfo":{"status":"ok","timestamp":1648635395650,"user_tz":-540,"elapsed":4230,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"6d022b29-4548-44cc-f71c-3b72613e90dd"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["이슈\n","코로나바이러스감염증-19 현황\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n"]}]},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","import urllib\n","\n","def get_article_info(driver, crawl_date, press_list, title_list, link_list, date_list, more_news_base_url=None, more_news=False):\n","    more_news_url_list = []\n","    while True:    \n","        page_html_source = driver.page_source\n","        url_soup = BeautifulSoup(page_html_source, 'lxml')\n","        \n","        more_news_infos = url_soup.select('a.news_more')\n","        \n","        if more_news:\n","            for more_news_info in more_news_infos:\n","                more_news_url = f\"{more_news_base_url}{more_news_info.get('href')}\"\n","\n","                more_news_url_list.append(more_news_url)\n","\n","        article_infos = url_soup.select(\"div.news_area\")\n","        \n","        if not article_infos:\n","            break\n","\n","        for article_info in article_infos:  \n","            press_info = article_info.select_one(\"div.info_group > a.info.press\")\n","            \n","            if press_info is None:\n","                press_info = article_info.select_one(\"div.info_group > span.info.press\")\n","            article = article_info.select_one(\"a.news_tit\")\n","            \n","            press = press_info.text.replace(\"언론사 선정\", \"\")\n","            title = article.get('title')\n","            link = article.get('href')\n","\n","#             print(f\"press - {press} / title - {title} / link - {link}\")\n","            press_list.append(press)\n","            title_list.append(title)\n","            link_list.append(link)\n","            date_list.append(crawl_date)\n","\n","        time.sleep(2.0)\n","                      \n","                      \n","        next_button_status = url_soup.select_one(\"a.btn_next\").get(\"aria-disabled\")\n","        \n","        if next_button_status == 'true':\n","            break\n","        \n","        time.sleep(1.0)\n","        next_page_btn = driver.find_element_by_css_selector(\"a.btn_next\").click()      \n","    \n","    return press_list, title_list, link_list, more_news_url_list\n","    \n","    \n","\n","def get_naver_news_info_from_selenium(keyword, save_path, target_date, ds_de, sort=0, remove_duplicate=False):\n","    crawl_date = f\"{target_date[:4]}.{target_date[4:6]}.{target_date[6:]}\"\n","    #driver = wd.Chrome(\"./chromedriver\") # chromedriver 파일 경로\n","    options = wd.ChromeOptions()\n","    options.add_argument('--headless')        # Head-less 설정\n","    options.add_argument('--no-sandbox')\n","    options.add_argument('--disable-dev-shm-usage')\n","    driver = wd.Chrome('chromedriver', options=options)\n","\n","    encoded_keyword = urllib.parse.quote(keyword)\n","    url = f\"https://search.naver.com/search.naver?where=news&query={encoded_keyword}&sm=tab_opt&sort={sort}&photo=0&field=0&pd=3&ds={ds_de}&de={ds_de}&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom{target_date}to{target_date}&is_sug_officeid=0\"\n","    \n","    more_news_base_url = \"https://search.naver.com/search.naver\"\n","\n","    driver.get(url)\n","    \n","    press_list, title_list, link_list, date_list, more_news_url_list = [], [], [], [], []\n","    \n","    press_list, title_list, link_list, more_news_url_list = get_article_info(driver=driver, \n","                                                                             crawl_date=crawl_date, \n","                                                                             press_list=press_list, \n","                                                                             title_list=title_list, \n","                                                                             link_list=link_list,\n","                                                                             date_list=date_list,\n","                                                                             more_news_base_url=more_news_base_url,\n","                                                                             more_news=True)\n","    driver.close()\n","    \n","    if len(more_news_url_list) > 0:\n","        print(len(more_news_url_list))\n","        more_news_url_list = list(set(more_news_url_list))\n","        print(f\"->{len(more_news_url_list)}\")\n","        for more_news_url in more_news_url_list:\n","            driver = wd.Chrome(\"./chromedriver\")\n","            driver.get(more_news_url)\n","            \n","            press_list, title_list, link_list, more_news_url_list = get_article_info(driver=driver, \n","                                                                             crawl_date=crawl_date, \n","                                                                             press_list=press_list, \n","                                                                             title_list=title_list, \n","                                                                             link_list=link_list,\n","                                                                             date_list=date_list)\n","            driver.close()\n","    article_df = pd.DataFrame({\"날짜\": date_list, \"언론사\": press_list, \"제목\": title_list, \"링크\": link_list})\n","    \n","    print(f\"extract article num : {len(article_df)}\")\n","    if remove_duplicate:\n","        article_df = article_df.drop_duplicates(['링크'], keep='first')\n","        print(f\"after remove duplicate -> {len(article_df)}\")\n","    \n","    article_df.to_excel(save_path, index=False)"],"metadata":{"id":"pBRIbwSJUXJ-","executionInfo":{"status":"ok","timestamp":1648635468041,"user_tz":-540,"elapsed":315,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"dLjaGZPHVPf_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","def crawl_news_data(keyword, year, month, start_day, end_day, save_path):\n","    for day in tqdm(range(start_day, end_day+1)):\n","        date_time_obj = datetime(year=year, month=month, day=day)\n","        target_date = date_time_obj.strftime(\"%Y%m%d\")\n","        ds_de = date_time_obj.strftime(\"%Y.%m.%d\")\n","\n","        get_naver_news_info_from_selenium(keyword=keyword, save_path=f\"{save_path}/{keyword}/{target_date}_{keyword}_.xlsx\", target_date=target_date, ds_de=ds_de, remove_duplicate=False)"],"metadata":{"id":"wRy5qeL0UXnz","executionInfo":{"status":"ok","timestamp":1648635479563,"user_tz":-540,"elapsed":2,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["keywords = ['틴더', '토스', '야놀자', '당근마켓', '아프리카tv', '온플법', '매치그룹']\n","save_path = \"./naver_news_article_2022\"\n","\n","for keyword in keywords:\n","    os.makedirs(f\"{save_path}/{keyword}\")"],"metadata":{"id":"1rlf8yDQVQG4","executionInfo":{"status":"ok","timestamp":1648635574164,"user_tz":-540,"elapsed":1,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["for keyword in keywords:\n","    print(f\"start keyword - {keyword} crawling ...\")\n","    crawl_news_data(keyword=keyword, year=2022, month=1, start_day=1, end_day=13, save_path=save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":852},"id":"1K3nec8hVdSR","executionInfo":{"status":"error","timestamp":1648635692377,"user_tz":-540,"elapsed":87081,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"a3249e78-cc73-4d00-c7a7-ad4c565f76b1"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["start keyword - 틴더 crawling ...\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/13 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 0\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 2/13 [00:05<00:30,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 0\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 3/13 [00:08<00:27,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 0\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███       | 4/13 [00:13<00:33,  3.76s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 3\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 5/13 [00:19<00:35,  4.40s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 2\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 6/13 [00:21<00:26,  3.83s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 0\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 7/13 [00:26<00:25,  4.25s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 1\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 8/13 [00:30<00:19,  3.91s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 0\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 9/13 [00:35<00:17,  4.30s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 1\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 10/13 [00:40<00:13,  4.59s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 2\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▍ | 11/13 [00:44<00:08,  4.46s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 0\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 12/13 [00:51<00:05,  5.20s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:57<00:00,  4.46s/it]\n"]},{"output_type":"stream","name":"stdout","text":["extract article num : 1\n","start keyword - 토스 crawling ...\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n","  8%|▊         | 1/13 [00:10<02:03, 10.27s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:90: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n","  8%|▊         | 1/13 [00:29<05:48, 29.06s/it]"]},{"output_type":"stream","name":"stdout","text":["2\n","->2\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"WebDriverException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                             \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                             creationflags=self.creationflags)\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './chromedriver': './chromedriver'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-6953ddae3426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"start keyword - {keyword} crawling ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcrawl_news_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2022\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_day\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_day\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-246aa370221b>\u001b[0m in \u001b[0;36mcrawl_news_data\u001b[0;34m(keyword, year, month, start_day, end_day, save_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mds_de\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate_time_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y.%m.%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mget_naver_news_info_from_selenium\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{save_path}/{keyword}/{target_date}_{keyword}_.xlsx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_de\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_de\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-d1a56a31e4b6>\u001b[0m in \u001b[0;36mget_naver_news_info_from_selenium\u001b[0;34m(keyword, save_path, target_date, ds_de, sort, remove_duplicate)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"->{len(more_news_url_list)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmore_news_url\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmore_news_url_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./chromedriver\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmore_news_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[1;32m     71\u001b[0m                                         \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                                         \u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_capabilities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                                         service_log_path, service, keep_alive)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 raise WebDriverException(\n\u001b[1;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[0;32m---> 83\u001b[0;31m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[1;32m     84\u001b[0m                 )\n\u001b[1;32m     85\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mWebDriverException\u001b[0m: Message: 'chromedriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import glob\n","import os\n","\n","def merge_excel_files(file_path, file_format, save_path, save_format, columns=None):\n","    merge_df = pd.DataFrame()\n","    file_list = file_list = [f\"{file_path}/{file}\" for file in os.listdir(file_path) if file_format in file]\n","    \n","    for file in file_list:\n","        if file_format == \".xlsx\":\n","            file_df = pd.read_excel(file)\n","        else:\n","            file_df = pd.read_csv(file)\n","        \n","        if columns is None:\n","            columns = file_df.columns\n","            \n","        temp_df = pd.DataFrame(file_df, columns=columns)\n","        \n","        merge_df = merge_df.append(temp_df)\n","        \n","    if save_format == \".xlsx\":\n","        merge_df.to_excel(save_path, index=False)\n","    else:\n","        merge_df.to_csv(save_path, index=False)\n","        \n","\n","if __name__ == \"__main__\":\n","    for keyword in keywords:\n","        merge_excel_files(file_path=f\"/naver_news_article_2022/{keyword}\", file_format=\".xlsx\", \n","                          save_path=f\"/naver_news_article_2022/{keyword}/20220101~20220113_{keyword}_네이버_기사.xlsx\", save_format=\".xlsx\")"],"metadata":{"id":"q-FLhdgZVu11"},"execution_count":null,"outputs":[]}]}